{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "004de6046f1b3d314f33fdb43a2dc798b2646e5600efd8df5066c8b63a00ff6d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 数据预处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "特征维度： (1797, 64)\n标签维度： (1797,)\n"
     ]
    }
   ],
   "source": [
    "print(\"特征维度：\", digits[\"data\"].shape)\n",
    "print(\"标签维度：\", digits[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "标签分布： [0 1 2 3 4 5 6 7 8 9]\n标签类别数目： 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "target_distribute = np.unique(digits[\"target\"])\n",
    "print(\"标签分布：\", target_distribute)\n",
    "print(\"标签类别数目：\", len(target_distribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(digits[\"data\"])\n",
    "x_scaled = scaler.transform(digits[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "原始数据的第一个样本：\n[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n数据标准化后的第一个样本：\n[ 0.         -0.33501649 -0.04308102  0.27407152 -0.66447751 -0.84412939\n -0.40972392 -0.12502292 -0.05907756 -0.62400926  0.4829745   0.75962245\n -0.05842586  1.12772113  0.87958306 -0.13043338 -0.04462507  0.11144272\n  0.89588044 -0.86066632 -1.14964846  0.51547187  1.90596347 -0.11422184\n -0.03337973  0.48648928  0.46988512 -1.49990136 -1.61406277  0.07639777\n  1.54181413 -0.04723238  0.          0.76465553  0.05263019 -1.44763006\n -1.73666443  0.04361588  1.43955804  0.         -0.06134367  0.8105536\n  0.63011714 -1.12245711 -1.06623158  0.66096475  0.81845076 -0.08874162\n -0.03543326  0.74211893  1.15065212 -0.86867056  0.11012973  0.53761116\n -0.75743581 -0.20978513 -0.02359646 -0.29908135  0.08671869  0.20829258\n -0.36677122 -1.14664746 -0.5056698  -0.19600752]\n"
     ]
    }
   ],
   "source": [
    "print(\"原始数据的第一个样本：\")\n",
    "print(digits[\"data\"][0])\n",
    "print(\"数据标准化后的第一个样本：\")\n",
    "print(x_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_scaled\n",
    "y = digits[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# test_size: float or int, default=0.25\n",
    "# shuffle: bool, default=True\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "将25%的数据集划分给测试集\n(1347, 64)\n(450, 64)\n(1347,)\n(450,)\n"
     ]
    }
   ],
   "source": [
    "print(\"将25%的数据集划分给测试集\")\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "## 训练多层感知机"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(30, 30, 30),\n",
       "              max_iter=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 30, 30), activation='logistic', max_iter=1000)\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "预测并观察结果\n              precision    recall  f1-score   support\n\n           0       1.00      0.96      0.98        52\n           1       0.87      0.96      0.91        48\n           2       0.89      0.92      0.90        36\n           3       0.90      0.92      0.91        50\n           4       0.89      0.97      0.93        34\n           5       0.97      0.94      0.96        36\n           6       0.96      1.00      0.98        47\n           7       0.90      0.95      0.92        38\n           8       0.96      0.88      0.92        50\n           9       0.96      0.85      0.90        59\n\n    accuracy                           0.93       450\n   macro avg       0.93      0.93      0.93       450\nweighted avg       0.93      0.93      0.93       450\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predicted = mlp.predict(x_test)\n",
    "print(\"预测并观察结果\")\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "最佳效果：0.966\n",
      "最优参数：\n",
      "\tmlp__activation: 'relu'\n",
      "\tmlp__solver: 'adam'\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        52\n",
      "           1       0.94      0.98      0.96        48\n",
      "           2       0.90      1.00      0.95        36\n",
      "           3       0.94      0.92      0.93        50\n",
      "           4       0.92      0.97      0.94        34\n",
      "           5       0.95      0.97      0.96        36\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       0.97      1.00      0.99        38\n",
      "           8       0.94      0.90      0.92        50\n",
      "           9       0.96      0.90      0.93        59\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.96      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "if __name__ == '__main__':\n",
    "    pipeline = Pipeline([\n",
    "        ('mlp', MLPClassifier(hidden_layer_sizes=(30, 30, 30), max_iter=1000))\n",
    "    ])\n",
    "    parameters = {\n",
    "        'mlp__activation': ('identity','logistic','tanh','relu'),\n",
    "         'mlp__solver': ('lbfgs','sgd','adam')\n",
    "    }\n",
    "    grid_search = GridSearchCV(pipeline, parameters, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print('最佳效果：%0.3f' % grid_search.best_score_)\n",
    "    print('最优参数：')\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "\n",
    "    predictions = grid_search.predict(x_test)\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}